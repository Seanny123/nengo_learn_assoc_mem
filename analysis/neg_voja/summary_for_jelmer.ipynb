{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the importance of analytically finding the decoders for matching reaction times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "from nengo.utils.ensemble import tuning_curves\n",
    "import nengolib\n",
    "import nengo_spa as spa\n",
    "\n",
    "from nengo_learn_assoc_mem.utils import (BasicVecFeed, meg_from_spikes, numpy_bytes_to_str,\n",
    "                                         gen_added_strings, norm_spa_vecs)\n",
    "from nengo_learn_assoc_mem.paths import data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoders', 'fan1', 'fan2', 'foil1', 'foil2', 't_range', 'vocab_strings', 'vocab_vectors']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(data_path, \"neg_voja_enc.h5\"), \"r\") as fi:\n",
    "    print(list(fi.keys()))\n",
    "\n",
    "    fan1 = numpy_bytes_to_str(fi['fan1'])\n",
    "    fan2 = numpy_bytes_to_str(fi['fan2'])\n",
    "    foil1 = numpy_bytes_to_str(fi['foil1'])\n",
    "    foil2 = numpy_bytes_to_str(fi['foil2'])\n",
    "\n",
    "    v_strs = numpy_bytes_to_str(fi['vocab_strings'])\n",
    "    v_vecs = list(fi['vocab_vectors'])\n",
    "    dimensions = fi['vocab_vectors'].attrs['dimensions']\n",
    "    \n",
    "    fin_enc = np.array(fi['encoders'])\n",
    "    n_neurons = fin_enc.shape[0]\n",
    "    intercepts = [fi['encoders'].attrs['intercept']] * n_neurons\n",
    "    seed = fi['encoders'].attrs['seed']\n",
    "\n",
    "    dt = fi['t_range'].attrs['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(data_path, \"bcm_rec_pos_match_weights.h5\"), \"r\") as fi:\n",
    "    \n",
    "    rec_weights = np.array(fi['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = spa.Vocabulary(dimensions)\n",
    "for val, vec in zip(v_strs, v_vecs):\n",
    "    vocab.add(val, vec)\n",
    "\n",
    "fan1_pair_vecs = norm_spa_vecs(vocab, fan1)\n",
    "fan2_pair_vecs = norm_spa_vecs(vocab, fan2)\n",
    "foil1_pair_vecs = norm_spa_vecs(vocab, foil1)\n",
    "foil2_pair_vecs = norm_spa_vecs(vocab, foil2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fan_vecs = fan1_pair_vecs + fan2_pair_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_pause = 0.2\n",
    "t_present = 0.3\n",
    "\n",
    "t_each = t_pause + t_present\n",
    "td_each = int(t_each/dt)\n",
    "td_pause = int(t_pause/dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fan1_slc = slice(td_pause, td_each*len(fan1_pair_vecs)+td_pause)\n",
    "fan2_slc = slice(fan1_slc.stop, fan1_slc.stop+td_each*len(fan2_pair_vecs))\n",
    "foil1_slc = slice(fan2_slc.stop, fan2_slc.stop+td_each*len(foil1_pair_vecs))\n",
    "foil2_slc = slice(foil1_slc.stop, foil1_slc.stop+td_each*len(foil2_pair_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SlcStim = namedtuple(\"Stim\", ['fan_num', 'targ', 'vecs', 'slc'])\n",
    "\n",
    "slc_stim_vecs = {\"fan1\": SlcStim(1, True, np.array(fan1_pair_vecs), fan1_slc),\n",
    "                 \"fan2\": SlcStim(2, True, np.array(fan2_pair_vecs), fan2_slc),\n",
    "                 \"foil1\": SlcStim(1, False, np.array(foil1_pair_vecs), foil1_slc),\n",
    "                 \"foil2\": SlcStim(2, False, np.array(foil2_pair_vecs), foil2_slc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(feed_vecs, rec_weights):\n",
    "    feed = BasicVecFeed(feed_vecs, feed_vecs, t_present, dimensions, len(feed_vecs), t_pause)\n",
    "\n",
    "    with nengo.Network(seed=seed) as learned_model:\n",
    "        in_nd = nengo.Node(feed.feed)\n",
    "        correct = nengo.Node(feed.get_answer)\n",
    "        learning = nengo.Node(lambda t: -feed.paused)\n",
    "        pause = nengo.Node(lambda t: feed.paused)\n",
    "        output = nengo.Node(size_in=dimensions)\n",
    "\n",
    "        ens = nengo.Ensemble(n_neurons, dimensions,\n",
    "                             encoders=fin_enc.copy(), intercepts=intercepts, seed=seed)\n",
    "\n",
    "        nengo.Connection(in_nd, ens)\n",
    "        conn_out = nengo.Connection(ens, output, learning_rule_type=nengo.PES(1e-2))\n",
    "        nengo.Connection(ens.neurons, ens.neurons, transform=rec_weights)\n",
    "        nengo.Connection(pause, ens.neurons, transform=-10*np.ones((n_neurons, 1)))\n",
    "\n",
    "        # Error flow node\n",
    "        pes_learn_control = nengo.Node(\n",
    "            lambda t, x: x[:-1] if x[-1] > 0 else x[:-1] * 0,\n",
    "            size_in=dimensions + 1)\n",
    "        nengo.Connection(pes_learn_control,\n",
    "                         conn_out.learning_rule)\n",
    "\n",
    "        # Error calculation connections\n",
    "        nengo.Connection(output, pes_learn_control[:-1],\n",
    "                         synapse=None)\n",
    "        nengo.Connection(correct, pes_learn_control[:-1],\n",
    "                         transform=-1, synapse=None)\n",
    "        # Control connection\n",
    "        nengo.Connection(learning, pes_learn_control[-1],\n",
    "                         synapse=None)\n",
    "\n",
    "        p_in = nengo.Probe(in_nd)\n",
    "        p_cor = nengo.Probe(correct, synapse=None)\n",
    "        p_dec = nengo.Probe(conn_out, 'weights', sample_every=0.1)\n",
    "        p_out = nengo.Probe(output, synapse=0.01)\n",
    "\n",
    "    with nengo.Simulator(learned_model) as learned_sim:\n",
    "        learned_sim.run(len(feed_vecs)*t_each + t_pause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(feed_vecs):\n",
    "    feed = BasicVecFeed(feed_vecs, feed_vecs, t_present, dimensions, len(feed_vecs), t_pause)\n",
    "\n",
    "    with nengo.Network(seed=seed) as test_model:\n",
    "        in_nd = nengo.Node(feed.feed)\n",
    "        correct = nengo.Node(feed.get_answer)\n",
    "        learning = nengo.Node(lambda t: -feed.paused)\n",
    "        output = nengo.Node(size_in=dimensions)\n",
    "\n",
    "        ens = nengo.Ensemble(n_neurons, dimensions,\n",
    "                             encoders=fin_enc.copy(), intercepts=intercepts, seed=seed)\n",
    "\n",
    "        nengo.Connection(in_nd, ens)\n",
    "        nengo.Connection(ens.neurons, ens.neurons, transform=rec_weights, synapse=0.01)\n",
    "        nengo.Connection(ens.neurons, output, transform=dec)\n",
    "\n",
    "        p_in = nengo.Probe(in_nd)\n",
    "        p_cor = nengo.Probe(correct, synapse=None)\n",
    "        p_out = nengo.Probe(output, synapse=0.01)\n",
    "\n",
    "    with nengo.Simulator(test_model) as test_sim:\n",
    "        test_sim.run(len(feed_vecs)*t_each + t_pause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn with no recurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn with negative-only recurrent weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn with negative and positive recurrent weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find decoders analytically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:01.                                                                                   \n"
     ]
    }
   ],
   "source": [
    "with nengo.Network(seed=seed) as decode_model:\n",
    "    ens = nengo.Ensemble(n_neurons, dimensions,\n",
    "                         encoders=fin_enc.copy(), intercepts=intercepts, seed=seed)\n",
    "\n",
    "with nengo.Simulator(decode_model) as decode_sim:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = nengo.solvers.LstsqL2(reg=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, activities = tuning_curves(ens, decode_sim, inputs=np.array(feed_vecs))\n",
    "dec, rmse = solver(activities, feed_vecs)\n",
    "dec = dec.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
